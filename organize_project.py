#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®ç»“æ„æ•´ç†è„šæœ¬
å°†æ‰€æœ‰ç»“æœæ–‡ä»¶æ•´ç†åˆ°ç»Ÿä¸€çš„ results æ–‡ä»¶å¤¹ä¸‹
"""

import os
import shutil
from pathlib import Path
import json
from datetime import datetime


def create_results_structure():
    """åˆ›å»ºç»Ÿä¸€çš„ç»“æœæ–‡ä»¶å¤¹ç»“æ„"""
    base_dir = Path("results")
    
    # åˆ›å»ºä¸»è¦ç»“æœç›®å½•
    directories = [
        "asr_results",           # ASRè¯­éŸ³è¯†åˆ«ç»“æœ
        "training_results",      # æ¨¡å‹è®­ç»ƒç»“æœ
        "analysis_results",      # åˆ†æç»“æœ
        "extracted_results",     # æå–çš„ç»“æœæ–‡ä»¶
        "oss_backups",          # OSSå¤‡ä»½æ–‡ä»¶
        "logs"                  # æ—¥å¿—æ–‡ä»¶
    ]
    
    for dir_name in directories:
        dir_path = base_dir / dir_name
        dir_path.mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {dir_path}")
    
    return base_dir


def move_asr_results():
    """ç§»åŠ¨ASRè¯†åˆ«ç»“æœæ–‡ä»¶"""
    print("\nğŸ“ æ•´ç†ASRè¯†åˆ«ç»“æœ...")
    
    asr_dir = Path("results/asr_results")
    moved_count = 0
    
    # ç§»åŠ¨æ ¹ç›®å½•ä¸‹çš„è¯†åˆ«ç»“æœæ–‡ä»¶
    for pattern in ["recognition_results_*.json", "recognition_results_*.txt"]:
        for file_path in Path(".").glob(pattern):
            if file_path.is_file():
                target_path = asr_dir / file_path.name
                shutil.move(str(file_path), str(target_path))
                print(f"  ğŸ“„ ç§»åŠ¨: {file_path.name}")
                moved_count += 1
    
    # ç§»åŠ¨datasetç›®å½•ä¸‹çš„è¯†åˆ«ç»“æœ
    dataset_voice_dir = Path("dataset/datasets/voice_25h")
    if dataset_voice_dir.exists():
        for json_file in dataset_voice_dir.rglob("*.json"):
            if "recognition" in json_file.name or any(keyword in json_file.name for keyword in ["_analysis", "_result"]):
                target_path = asr_dir / json_file.name
                if not target_path.exists():
                    shutil.copy2(str(json_file), str(target_path))
                    print(f"  ğŸ“„ å¤åˆ¶: {json_file.name}")
                    moved_count += 1
        
        for txt_file in dataset_voice_dir.rglob("*.txt"):
            if "analysis" in txt_file.name or "recognition" in txt_file.name:
                target_path = asr_dir / txt_file.name
                if not target_path.exists():
                    shutil.copy2(str(txt_file), str(target_path))
                    print(f"  ğŸ“„ å¤åˆ¶: {txt_file.name}")
                    moved_count += 1
    
    print(f"ğŸ“Š ASRç»“æœæ–‡ä»¶: å¤„ç†äº† {moved_count} ä¸ªæ–‡ä»¶")
    return moved_count


def move_training_results():
    """ç§»åŠ¨è®­ç»ƒç»“æœæ–‡ä»¶å¤¹"""
    print("\nğŸ¯ æ•´ç†è®­ç»ƒç»“æœ...")
    
    training_dir = Path("results/training_results")
    moved_count = 0
    
    # ç§»åŠ¨modelç›®å½•ä¸‹çš„ç»“æœæ–‡ä»¶å¤¹
    model_dir = Path("model")
    if model_dir.exists():
        for item in model_dir.iterdir():
            if item.is_dir() and "results" in item.name:
                target_path = training_dir / item.name
                if not target_path.exists():
                    shutil.move(str(item), str(target_path))
                    print(f"  ğŸ“ ç§»åŠ¨: {item.name}")
                    moved_count += 1
    
    # ç§»åŠ¨å…¶ä»–è®­ç»ƒç›¸å…³æ–‡ä»¶
    for pattern in ["*.pt", "*.pth", "*.ckpt"]:
        for file_path in Path(".").glob(pattern):
            if file_path.is_file() and "yolo" in file_path.name.lower():
                target_path = training_dir / file_path.name
                if not target_path.exists():
                    shutil.move(str(file_path), str(target_path))
                    print(f"  ğŸ“„ ç§»åŠ¨: {file_path.name}")
                    moved_count += 1
    
    print(f"ğŸ“Š è®­ç»ƒç»“æœ: å¤„ç†äº† {moved_count} ä¸ªé¡¹ç›®")
    return moved_count


def move_analysis_results():
    """ç§»åŠ¨åˆ†æç»“æœæ–‡ä»¶"""
    print("\nğŸ“ˆ æ•´ç†åˆ†æç»“æœ...")
    
    analysis_dir = Path("results/analysis_results")
    moved_count = 0
    
    # ç§»åŠ¨åˆ†æç›¸å…³çš„å›¾ç‰‡å’Œæ–‡ä»¶
    for pattern in ["*_test.png", "*_analysis.png", "*_plot.png", "*.html"]:
        for file_path in Path(".").glob(pattern):
            if file_path.is_file():
                target_path = analysis_dir / file_path.name
                if not target_path.exists():
                    shutil.move(str(file_path), str(target_path))
                    print(f"  ğŸ“„ ç§»åŠ¨: {file_path.name}")
                    moved_count += 1
    
    # ç§»åŠ¨catboost_info
    catboost_dir = Path("catboost_info")
    if catboost_dir.exists():
        target_path = analysis_dir / "catboost_info"
        if not target_path.exists():
            shutil.move(str(catboost_dir), str(target_path))
            print(f"  ğŸ“ ç§»åŠ¨: catboost_info")
            moved_count += 1
    
    print(f"ğŸ“Š åˆ†æç»“æœ: å¤„ç†äº† {moved_count} ä¸ªé¡¹ç›®")
    return moved_count


def move_extracted_files():
    """ç§»åŠ¨æå–çš„æ–‡ä»¶"""
    print("\nğŸ“¦ æ•´ç†æå–çš„æ–‡ä»¶...")
    
    extracted_dir = Path("results/extracted_results")
    moved_count = 0
    
    # ç§»åŠ¨å¯èƒ½çš„æå–ç»“æœç›®å½•
    for pattern in ["asr_results*", "extracted_*", "*_extracted"]:
        for item in Path(".").glob(pattern):
            if item.is_dir():
                target_path = extracted_dir / item.name
                if not target_path.exists():
                    shutil.move(str(item), str(target_path))
                    print(f"  ğŸ“ ç§»åŠ¨: {item.name}")
                    moved_count += 1
    
    print(f"ğŸ“Š æå–æ–‡ä»¶: å¤„ç†äº† {moved_count} ä¸ªé¡¹ç›®")
    return moved_count


def update_script_paths():
    """æ›´æ–°è„šæœ¬ä¸­çš„è·¯å¾„å¼•ç”¨"""
    print("\nğŸ”§ æ›´æ–°è„šæœ¬è·¯å¾„å¼•ç”¨...")
    
    # éœ€è¦æ›´æ–°çš„è„šæœ¬æ–‡ä»¶
    scripts_to_update = [
        "model/voice_asr.py",
        "extract_asr_simple.py",
        "extract_asr_results.py"
    ]
    
    updated_count = 0
    
    for script_path in scripts_to_update:
        script_file = Path(script_path)
        if script_file.exists():
            try:
                with open(script_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æ›´æ–°é»˜è®¤è¾“å‡ºè·¯å¾„
                original_content = content
                content = content.replace(
                    'default="asr_results"',
                    'default="results/extracted_results/asr_results"'
                )
                content = content.replace(
                    'output_dir = "asr_results"',
                    'output_dir = "results/extracted_results/asr_results"'
                )
                
                if content != original_content:
                    with open(script_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    print(f"  ğŸ“ æ›´æ–°: {script_path}")
                    updated_count += 1
                    
            except Exception as e:
                print(f"  âš ï¸ æ›´æ–°å¤±è´¥: {script_path} - {e}")
    
    print(f"ğŸ“Š è„šæœ¬æ›´æ–°: å¤„ç†äº† {updated_count} ä¸ªæ–‡ä»¶")
    return updated_count


def create_summary_report():
    """åˆ›å»ºæ•´ç†æ±‡æ€»æŠ¥å‘Š"""
    print("\nğŸ“‹ åˆ›å»ºæ•´ç†æ±‡æ€»æŠ¥å‘Š...")
    
    results_dir = Path("results")
    report_file = results_dir / "organization_summary.txt"
    
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("é¡¹ç›®ç»“æ„æ•´ç†æ±‡æ€»æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n")
            f.write(f"æ•´ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # ç»Ÿè®¡å„ç›®å½•çš„æ–‡ä»¶æ•°é‡
            for subdir in results_dir.iterdir():
                if subdir.is_dir():
                    file_count = len(list(subdir.rglob("*")))
                    f.write(f"{subdir.name}: {file_count} ä¸ªé¡¹ç›®\n")
            
            f.write(f"\nç›®å½•ç»“æ„:\n")
            f.write("-" * 30 + "\n")
            
            # é€’å½’æ˜¾ç¤ºç›®å½•ç»“æ„
            def write_tree(path, prefix="", file_handle=f):
                items = sorted(path.iterdir())
                for i, item in enumerate(items):
                    is_last = i == len(items) - 1
                    current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                    file_handle.write(f"{prefix}{current_prefix}{item.name}\n")
                    
                    if item.is_dir() and len(list(item.iterdir())) > 0:
                        next_prefix = prefix + ("    " if is_last else "â”‚   ")
                        write_tree(item, next_prefix, file_handle)
            
            write_tree(results_dir)
        
        print(f"ğŸ“‹ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
    except Exception as e:
        print(f"âš ï¸ åˆ›å»ºæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")


def main():
    print("ğŸš€ å¼€å§‹æ•´ç†é¡¹ç›®ç»“æ„...")
    print("=" * 50)
    
    # åˆ›å»ºç»“æœç›®å½•ç»“æ„
    create_results_structure()
    
    # ç§»åŠ¨å„ç±»æ–‡ä»¶
    asr_count = move_asr_results()
    training_count = move_training_results()
    analysis_count = move_analysis_results()
    extracted_count = move_extracted_files()
    
    # æ›´æ–°è„šæœ¬è·¯å¾„
    script_count = update_script_paths()
    
    # åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
    create_summary_report()
    
    # æ˜¾ç¤ºæ€»ç»“
    print("\nğŸ‰ é¡¹ç›®ç»“æ„æ•´ç†å®Œæˆ!")
    print("=" * 50)
    print(f"ğŸ“ ASRç»“æœæ–‡ä»¶: {asr_count} ä¸ª")
    print(f"ğŸ¯ è®­ç»ƒç»“æœ: {training_count} ä¸ª")
    print(f"ğŸ“ˆ åˆ†æç»“æœ: {analysis_count} ä¸ª")
    print(f"ğŸ“¦ æå–æ–‡ä»¶: {extracted_count} ä¸ª")
    print(f"ğŸ“ è„šæœ¬æ›´æ–°: {script_count} ä¸ª")
    print(f"\nğŸ“‹ æ‰€æœ‰ç»“æœæ–‡ä»¶å·²æ•´ç†åˆ° 'results/' ç›®å½•ä¸‹")
    print(f"ğŸ“„ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: results/organization_summary.txt")


if __name__ == "__main__":
    main()
