#!/usr/bin/env python3
"""
çƒ­åŠ›å›¾å¯¹æ¯”å­¦ä¹ æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æè¿è¡Œè„šæœ¬
ç®€åŒ–ç‰ˆæœ¬ï¼Œè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹å’Œæ•°æ®é›†
"""

import os
import sys
from pathlib import Path
import glob
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from interpretability_analysis import ThermalInterpretabilityAnalyzer
import torch

def detect_model_asymmetry_mode(model_path: str) -> bool:
    """æ£€æµ‹æ¨¡å‹æ˜¯å¦ä½¿ç”¨ä¸å¯¹ç§°åˆ†ææ¨¡å¼"""
    try:
        # åŠ è½½æ¨¡å‹çŠ¶æ€å­—å…¸
        state_dict = torch.load(model_path, map_location='cpu')

        # æ£€æŸ¥conv1å±‚çš„è¾“å…¥é€šé“æ•°
        conv1_weight_key = 'backbone.conv1.weight'
        if conv1_weight_key in state_dict:
            conv1_shape = state_dict[conv1_weight_key].shape
            input_channels = conv1_shape[1]  # [out_channels, in_channels, H, W]

            if input_channels == 6:
                return True  # ä¸å¯¹ç§°åˆ†ææ¨¡å¼
            elif input_channels == 3:
                return False  # æ ‡å‡†æ¨¡å¼
            else:
                print(f"è­¦å‘Š: æ£€æµ‹åˆ°å¼‚å¸¸çš„è¾“å…¥é€šé“æ•°: {input_channels}")
                return False
        else:
            print(f"è­¦å‘Š: åœ¨æ¨¡å‹ä¸­æœªæ‰¾åˆ° {conv1_weight_key}")
            return False

    except Exception as e:
        print(f"è­¦å‘Š: æ£€æµ‹æ¨¡å‹æ¨¡å¼æ—¶å‡ºé”™: {e}")
        print("é»˜è®¤ä½¿ç”¨æ ‡å‡†æ¨¡å¼ (3é€šé“)")
        return False

def find_latest_model(base_dir: str = "./model/contrastive_thermal_classifier_results") -> str:
    """æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒæ¨¡å‹"""
    base_path = Path(base_dir)
    if not base_path.exists():
        raise FileNotFoundError(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {base_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰è¿è¡Œç›®å½•
    run_dirs = [d for d in base_path.iterdir() if d.is_dir() and d.name.startswith("run_")]
    
    if not run_dirs:
        raise FileNotFoundError(f"åœ¨ {base_dir} ä¸­æœªæ‰¾åˆ°è¿è¡Œç›®å½•")
    
    # æŒ‰æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„
    run_dirs.sort(key=lambda x: x.name, reverse=True)
    latest_run = run_dirs[0]
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    model_files = [
    #    latest_run / "best_contrastive_encoder.pth",
    #    latest_run / "contrastive_encoder.pth",
        latest_run / "best_classifier.pth"
    ]
    
    for model_file in model_files:
        if model_file.exists():
            print(f"æ‰¾åˆ°æ¨¡å‹: {model_file}")
            return str(model_file)
    
    raise FileNotFoundError(f"åœ¨ {latest_run} ä¸­æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")

def find_dataset_dir(base_dir: str = "./dataset/datasets") -> str:
    """æŸ¥æ‰¾æ•°æ®é›†ç›®å½•"""
    possible_dirs = [
        Path(base_dir) / "thermal_classification_cropped"
    ]
    
    for dataset_dir in possible_dirs:
        if dataset_dir.exists():
            print(f"æ‰¾åˆ°æ•°æ®é›†: {dataset_dir}")
            return str(dataset_dir)
    
    raise FileNotFoundError(f"åœ¨ {base_dir} ä¸­æœªæ‰¾åˆ°æ•°æ®é›†ç›®å½•")

def run_analysis_demo():
    """è¿è¡Œæ¼”ç¤ºåˆ†æ"""
    print("=== çƒ­åŠ›å›¾å¯¹æ¯”å­¦ä¹ æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ ===\n")
    
    try:
        # 1. æŸ¥æ‰¾æ¨¡å‹å’Œæ•°æ®é›†
        print("1. æŸ¥æ‰¾æœ€æ–°æ¨¡å‹å’Œæ•°æ®é›†...")
        model_path = find_latest_model()
        dataset_dir = find_dataset_dir()
        
        # 2. æ£€æµ‹æ¨¡å‹ç±»å‹å¹¶åˆ›å»ºåˆ†æå™¨
        print("\n2. æ£€æµ‹æ¨¡å‹ç±»å‹å¹¶åˆå§‹åŒ–åˆ†æå™¨...")

        # å°è¯•æ£€æµ‹æ¨¡å‹æ˜¯å¦ä½¿ç”¨ä¸å¯¹ç§°åˆ†æ
        use_asymmetry = detect_model_asymmetry_mode(model_path)
        print(f"æ£€æµ‹åˆ°æ¨¡å‹æ¨¡å¼: {'ä¸å¯¹ç§°åˆ†æ (6é€šé“)' if use_asymmetry else 'æ ‡å‡†æ¨¡å¼ (3é€šé“)'}")

        analyzer = ThermalInterpretabilityAnalyzer(
            model_path=model_path,
            use_asymmetry_analysis=use_asymmetry
        )
        
        # 3. æŸ¥æ‰¾æµ‹è¯•å›¾åƒ
        print("\n3. æŸ¥æ‰¾æµ‹è¯•å›¾åƒ...")
        
        # ä¼˜å…ˆæŸ¥æ‰¾ICASç±»åˆ«çš„å›¾åƒ
        icas_dir = Path(dataset_dir) / "icas"
        non_icas_dir = Path(dataset_dir) / "non_icas"
        
        test_images = []
        
        # ä»ICASç±»åˆ«é€‰æ‹©å‡ å¼ å›¾åƒ
        if icas_dir.exists():
            icas_images = list(icas_dir.glob("*.jpg"))[:3]  # æœ€å¤š3å¼ 
            test_images.extend(icas_images)
            print(f"æ‰¾åˆ° {len(icas_images)} å¼ ICASå›¾åƒ")
        
        # ä»Non-ICASç±»åˆ«é€‰æ‹©å‡ å¼ å›¾åƒ
        if non_icas_dir.exists():
            non_icas_images = list(non_icas_dir.glob("*.jpg"))[:3]  # æœ€å¤š3å¼ 
            test_images.extend(non_icas_images)
            print(f"æ‰¾åˆ° {len(non_icas_images)} å¼ Non-ICASå›¾åƒ")
        
        if not test_images:
            # å¦‚æœæ²¡æœ‰åˆ†ç±»ç›®å½•ï¼Œç›´æ¥ä»æ ¹ç›®å½•æŸ¥æ‰¾
            test_images = list(Path(dataset_dir).glob("**/*.jpg"))[:6]
            print(f"ä»æ ¹ç›®å½•æ‰¾åˆ° {len(test_images)} å¼ å›¾åƒ")
        
        if not test_images:
            raise FileNotFoundError("æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒ")
        
        print(f"æ€»å…±å°†åˆ†æ {len(test_images)} å¼ å›¾åƒ")
        
        # 4. è¿è¡Œåˆ†æ
        print("\n4. å¼€å§‹å¯è§£é‡Šæ€§åˆ†æ...")
        results = []
        
        for i, image_path in enumerate(test_images):
            print(f"\n--- åˆ†æå›¾åƒ {i+1}/{len(test_images)}: {image_path.name} ---")
            try:
                result = analyzer.analyze_single_image(str(image_path))
                results.append(result)
                print(f"âœ“ åˆ†æå®Œæˆ")
            except Exception as e:
                print(f"âœ— åˆ†æå¤±è´¥: {e}")
                continue
        
        # 5. ç”Ÿæˆæ±‡æ€»
        print(f"\n5. ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        analyzer._save_batch_results(results)
        
        # 6. æ˜¾ç¤ºç»“æœ
        print(f"\n=== åˆ†æå®Œæˆ ===")
        print(f"æˆåŠŸåˆ†æ: {len(results)} å¼ å›¾åƒ")
        print(f"è¾“å‡ºç›®å½•: {analyzer.output_dir}")
        print(f"\nè¾“å‡ºæ–‡ä»¶:")
        print(f"  ğŸ“Š åˆ†æç»“æœ: {analyzer.output_dir}/analysis_results.json")
        print(f"  ğŸ“‹ æ±‡æ€»æŠ¥å‘Š: {analyzer.output_dir}/summary_report.txt")
        print(f"  ğŸ”¥ çƒ­åŠ›å›¾: {analyzer.output_dir}/gradcam_heatmaps/")
        print(f"  ğŸ–¼ï¸  å åŠ å›¾åƒ: {analyzer.output_dir}/overlay_images/")
        
        # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
        if results:
            icas_predictions = sum(1 for r in results if r['predicted_class'] == 1)
            avg_confidence = sum(r['confidence'] for r in results) / len(results)
            
            print(f"\nğŸ“ˆ é¢„æµ‹ç»Ÿè®¡:")
            print(f"  ICASé¢„æµ‹: {icas_predictions}/{len(results)} ({icas_predictions/len(results)*100:.1f}%)")
            print(f"  å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return False

def run_custom_analysis():
    """è¿è¡Œè‡ªå®šä¹‰åˆ†æ"""
    print("=== è‡ªå®šä¹‰åˆ†ææ¨¡å¼ ===\n")
    
    # è·å–ç”¨æˆ·è¾“å…¥
    model_path = input("è¯·è¾“å…¥æ¨¡å‹è·¯å¾„ (å›è½¦ä½¿ç”¨è‡ªåŠ¨æŸ¥æ‰¾): ").strip()
    if not model_path:
        model_path = find_latest_model()
    
    image_input = input("è¯·è¾“å…¥å›¾åƒè·¯å¾„æˆ–ç›®å½• (å›è½¦ä½¿ç”¨é»˜è®¤æ•°æ®é›†): ").strip()
    if not image_input:
        image_input = find_dataset_dir()
    
    use_asymmetry_input = input("æ˜¯å¦ä½¿ç”¨ä¸å¯¹ç§°åˆ†æ? (y/n/auto, é»˜è®¤auto): ").strip().lower()

    if use_asymmetry_input == 'auto' or use_asymmetry_input == '':
        # è‡ªåŠ¨æ£€æµ‹æ¨¡å‹æ¨¡å¼
        use_asymmetry = detect_model_asymmetry_mode(model_path)
        print(f"è‡ªåŠ¨æ£€æµ‹æ¨¡å¼: {'ä¸å¯¹ç§°åˆ†æ (6é€šé“)' if use_asymmetry else 'æ ‡å‡†æ¨¡å¼ (3é€šé“)'}")
    else:
        use_asymmetry = use_asymmetry_input == 'y'

    # åˆ›å»ºåˆ†æå™¨
    analyzer = ThermalInterpretabilityAnalyzer(
        model_path=model_path,
        use_asymmetry_analysis=use_asymmetry
    )
    
    # åˆ¤æ–­è¾“å…¥æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›®å½•
    input_path = Path(image_input)
    
    if input_path.is_file():
        # å•æ–‡ä»¶åˆ†æ
        print(f"åˆ†æå•å¼ å›¾åƒ: {input_path}")
        _ = analyzer.analyze_single_image(str(input_path))
        print(f"åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {analyzer.output_dir}")
        
    elif input_path.is_dir():
        # ç›®å½•æ‰¹é‡åˆ†æ
        pattern = input("è¯·è¾“å…¥æ–‡ä»¶æ¨¡å¼ (é»˜è®¤*.jpg): ").strip()
        if not pattern:
            pattern = "*.jpg"
        
        print(f"æ‰¹é‡åˆ†æç›®å½•: {input_path}")
        print(f"æ–‡ä»¶æ¨¡å¼: {pattern}")
        
        results = analyzer.batch_analyze(str(input_path), pattern)
        print(f"æ‰¹é‡åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(results)} å¼ å›¾åƒ")
        print(f"ç»“æœä¿å­˜åˆ°: {analyzer.output_dir}")
        
    else:
        print(f"é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨ - {input_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("çƒ­åŠ›å›¾å¯¹æ¯”å­¦ä¹ æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æå·¥å…·\n")
    
    # æ£€æŸ¥å½“å‰å·¥ä½œç›®å½•
    if not Path("model").exists() or not Path("dataset").exists():
        print("âš ï¸  è­¦å‘Š: è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
        print("å½“å‰ç›®å½•:", os.getcwd())
        return
    
    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. æ¼”ç¤ºæ¨¡å¼ (è‡ªåŠ¨æŸ¥æ‰¾æ¨¡å‹å’Œæ•°æ®é›†)")
    print("2. è‡ªå®šä¹‰æ¨¡å¼ (æ‰‹åŠ¨æŒ‡å®šè·¯å¾„)")
    print("3. é€€å‡º")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
    
    if choice == '1':
        success = run_analysis_demo()
        if success:
            print("\nğŸ‰ æ¼”ç¤ºåˆ†æå®Œæˆ!")
        else:
            print("\nâŒ æ¼”ç¤ºåˆ†æå¤±è´¥!")
            
    elif choice == '2':
        run_custom_analysis()
        print("\nğŸ‰ è‡ªå®šä¹‰åˆ†æå®Œæˆ!")
        
    elif choice == '3':
        print("é€€å‡ºç¨‹åº")
        
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œé€€å‡ºç¨‹åº")

if __name__ == "__main__":
    main()
