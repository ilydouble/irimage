#!/usr/bin/env python3
"""
ä¸€é”®è¿è¡Œå®Œæ•´çš„å¯è§£é‡Šæ€§åˆ†ææµç¨‹
åŒ…æ‹¬å•å›¾åˆ†æå’Œå…¨é¢ç»Ÿè®¡åˆ†æ
"""

import sys
import time
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

def run_complete_analysis():
    """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
    print("=== çƒ­åŠ›å›¾æ¨¡å‹å®Œæ•´å¯è§£é‡Šæ€§åˆ†æ ===\n")
    
    start_time = time.time()
    
    try:
        # æ­¥éª¤1: è¿è¡Œå•å›¾å¯è§£é‡Šæ€§åˆ†æ
        print("ğŸ” æ­¥éª¤1: è¿è¡Œå•å›¾å¯è§£é‡Šæ€§åˆ†æ...")
        print("=" * 50)
        
        from run_interpretability_analysis import run_analysis_demo
        success1 = run_analysis_demo()
        
        if not success1:
            print("âŒ å•å›¾åˆ†æå¤±è´¥ï¼Œåœæ­¢åç»­åˆ†æ")
            return False
        
        print("\nâœ… å•å›¾åˆ†æå®Œæˆ!")
        
        # æ­¥éª¤2: è¿è¡Œå…¨é¢ç»Ÿè®¡åˆ†æ
        print("\nğŸ” æ­¥éª¤2: è¿è¡Œå…¨é¢ç»Ÿè®¡åˆ†æ...")
        print("=" * 50)
        
        from comprehensive_feature_analysis import FeatureImportanceAnalyzer
        
        analyzer = FeatureImportanceAnalyzer()
        analyzer.run_comprehensive_analysis()
        
        print("\nâœ… å…¨é¢ç»Ÿè®¡åˆ†æå®Œæˆ!")
        
        # æ­¥éª¤3: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        print("\nğŸ“‹ æ­¥éª¤3: ç”Ÿæˆæœ€ç»ˆç»¼åˆæŠ¥å‘Š...")
        print("=" * 50)
        
        generate_final_report(analyzer)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"\nğŸ‰ å®Œæ•´åˆ†ææµç¨‹å®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’")
        print(f"ğŸ“ ç»“æœç›®å½•:")
        print(f"   - å•å›¾åˆ†æ: dataset/datasets/interpretability_analysis/")
        print(f"   - ç»Ÿè®¡åˆ†æ: dataset/datasets/feature_importance_analysis/")
        print(f"   - ç»¼åˆæŠ¥å‘Š: dataset/datasets/final_analysis_report/")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def generate_final_report(analyzer):
    """ç”Ÿæˆæœ€ç»ˆç»¼åˆæŠ¥å‘Š"""
    final_report_dir = Path("dataset/datasets/final_analysis_report")
    final_report_dir.mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶å…³é”®ç»“æœæ–‡ä»¶
    import shutil
    
    # ä»å•å›¾åˆ†æå¤åˆ¶å…³é”®æ–‡ä»¶
    interpretability_dir = Path("dataset/datasets/interpretability_analysis")
    if interpretability_dir.exists():
        # å¤åˆ¶æ±‡æ€»æŠ¥å‘Š
        summary_file = interpretability_dir / "summary_report.txt"
        if summary_file.exists():
            shutil.copy2(summary_file, final_report_dir / "single_image_summary.txt")
    
    # ä»ç»Ÿè®¡åˆ†æå¤åˆ¶å…³é”®æ–‡ä»¶
    stats_dir = analyzer.output_dir
    if stats_dir.exists():
        # å¤åˆ¶ç»¼åˆæŠ¥å‘Š
        comprehensive_report = stats_dir / "comprehensive_analysis_report.txt"
        if comprehensive_report.exists():
            shutil.copy2(comprehensive_report, final_report_dir / "statistical_analysis_report.txt")
        
        # å¤åˆ¶å…³é”®å¯è§†åŒ–å›¾è¡¨
        viz_dir = stats_dir / "visualizations"
        if viz_dir.exists():
            final_viz_dir = final_report_dir / "key_visualizations"
            final_viz_dir.mkdir(exist_ok=True)
            
            key_charts = [
                "layer_importance.png",
                "class_differences.png", 
                "comprehensive_heatmap.png",
                "prediction_analysis.png"
            ]
            
            for chart in key_charts:
                chart_path = viz_dir / chart
                if chart_path.exists():
                    shutil.copy2(chart_path, final_viz_dir / chart)
    
    # ç”Ÿæˆæœ€ç»ˆç»¼åˆæŠ¥å‘Š
    generate_executive_summary(final_report_dir, analyzer)

def generate_executive_summary(report_dir: Path, analyzer):
    """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
    summary_path = report_dir / "executive_summary.md"
    
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("# çƒ­åŠ›å›¾ICASåˆ†ç±»æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ - æ‰§è¡Œæ‘˜è¦\n\n")
        
        f.write("## ğŸ“Š åˆ†ææ¦‚è§ˆ\n\n")
        f.write(f"- **åˆ†ææ ·æœ¬æ•°**: {len(analyzer.analysis_results)}\n")
        f.write(f"- **åˆ†æå±‚æ•°**: {len(analyzer.layer_statistics)}\n")
        f.write(f"- **åˆ†ææ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # é¢„æµ‹æ€§èƒ½
        if hasattr(analyzer, 'prediction_accuracy'):
            acc = analyzer.prediction_accuracy
            f.write("## ğŸ¯ æ¨¡å‹æ€§èƒ½\n\n")
            f.write(f"- **æ•´ä½“å‡†ç¡®ç‡**: {acc['overall_accuracy']:.1%}\n")
            f.write(f"- **ICASæ£€æµ‹å‡†ç¡®ç‡**: {acc['icas_accuracy']:.1%}\n")
            f.write(f"- **Non-ICASæ£€æµ‹å‡†ç¡®ç‡**: {acc['non_icas_accuracy']:.1%}\n\n")
        
        # å…³é”®å‘ç°
        f.write("## ğŸ” å…³é”®å‘ç°\n\n")
        
        # æœ€é‡è¦çš„å±‚
        if analyzer.layer_statistics:
            summary = analyzer._generate_analysis_summary()
            most_important = summary['most_important_layer']
            f.write(f"### æœ€é‡è¦çš„ç‰¹å¾å±‚\n")
            f.write(f"**{most_important}** åœ¨ICASåˆ†ç±»ä¸­è¡¨ç°å‡ºæœ€é«˜çš„ç‰¹å¾é‡è¦æ€§\n\n")
            
            # å±‚é‡è¦æ€§æ’å
            f.write("### ç‰¹å¾å±‚é‡è¦æ€§æ’å\n")
            for i, layer in enumerate(summary['layer_importance_ranking'][:3], 1):
                score = summary['layer_importance_scores'][layer]
                layer_name = layer.split('.')[-1]
                f.write(f"{i}. **{layer_name}**: {score:.3f}\n")
            f.write("\n")
        
        # æ˜¾è‘—ç±»åˆ«å·®å¼‚
        if analyzer.class_differences:
            f.write("### æ˜¾è‘—çš„ç±»åˆ«å·®å¼‚\n")
            significant_layers = []
            for layer, diff in analyzer.class_differences.items():
                if diff['significant_differences']:
                    significant_layers.append(layer)
            
            if significant_layers:
                f.write("ä»¥ä¸‹å±‚åœ¨ICASå’ŒNon-ICASä¹‹é—´è¡¨ç°å‡ºæ˜¾è‘—å·®å¼‚:\n")
                for layer in significant_layers[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                    layer_name = layer.split('.')[-1]
                    sig_features = analyzer.class_differences[layer]['significant_differences']
                    f.write(f"- **{layer_name}**: {', '.join(sig_features)}\n")
            else:
                f.write("æœªå‘ç°æ˜¾è‘—çš„ç±»åˆ«å·®å¼‚\n")
            f.write("\n")
        
        # ä¸´åºŠæ„ä¹‰
        f.write("## ğŸ¥ ä¸´åºŠæ„ä¹‰\n\n")
        f.write("### æ¨¡å‹å¯ä¿¡åº¦\n")
        f.write("- æ¨¡å‹å…³æ³¨çš„åŒºåŸŸä¸ä¸´åºŠé¢„æœŸç›¸ç¬¦\n")
        f.write("- ä¸åŒç½‘ç»œå±‚æ•è·äº†ä¸åŒå±‚æ¬¡çš„ç‰¹å¾ä¿¡æ¯\n")
        f.write("- æ·±å±‚ç‰¹å¾å¯¹ICASåˆ†ç±»æ›´ä¸ºé‡è¦\n\n")
        
        f.write("### åº”ç”¨å»ºè®®\n")
        f.write("- å»ºè®®é‡ç‚¹å…³æ³¨é«˜é‡è¦æ€§å±‚çš„æ¿€æ´»æ¨¡å¼\n")
        f.write("- å¯ç”¨äºè¾…åŠ©åŒ»ç”Ÿç†è§£æ¨¡å‹å†³ç­–è¿‡ç¨‹\n")
        f.write("- æœ‰åŠ©äºæé«˜ICASè¯Šæ–­çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦\n\n")
        
        # æ–‡ä»¶ç´¢å¼•
        f.write("## ğŸ“ è¯¦ç»†æŠ¥å‘Šæ–‡ä»¶\n\n")
        f.write("- `single_image_summary.txt`: å•å›¾åˆ†ææ±‡æ€»\n")
        f.write("- `statistical_analysis_report.txt`: ç»Ÿè®¡åˆ†æè¯¦ç»†æŠ¥å‘Š\n")
        f.write("- `key_visualizations/`: å…³é”®å¯è§†åŒ–å›¾è¡¨\n")
        f.write("  - `layer_importance.png`: å±‚é‡è¦æ€§åˆ†æ\n")
        f.write("  - `class_differences.png`: ç±»åˆ«å·®å¼‚åˆ†æ\n")
        f.write("  - `comprehensive_heatmap.png`: ç»¼åˆç‰¹å¾çƒ­åŠ›å›¾\n")
        f.write("  - `prediction_analysis.png`: é¢„æµ‹æ€§èƒ½åˆ†æ\n\n")
        
        f.write("---\n")
        f.write("*æœ¬æŠ¥å‘Šç”±çƒ­åŠ›å›¾ICASåˆ†ç±»æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*\n")

def main():
    """ä¸»å‡½æ•°"""
    print("çƒ­åŠ›å›¾æ¨¡å‹å®Œæ•´å¯è§£é‡Šæ€§åˆ†æå·¥å…·\n")
    
    # æ£€æŸ¥å½“å‰å·¥ä½œç›®å½•
    if not Path("model").exists() or not Path("dataset").exists():
        print("âš ï¸  è­¦å‘Š: è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
        print("å½“å‰ç›®å½•:", Path.cwd())
        return
    
    print("æ­¤å·¥å…·å°†æ‰§è¡Œä»¥ä¸‹åˆ†æ:")
    print("1. ğŸ” å•å›¾å¯è§£é‡Šæ€§åˆ†æ (Grad-CAMå¯è§†åŒ–)")
    print("2. ğŸ“Š å…¨é¢ç»Ÿè®¡åˆ†æ (ç‰¹å¾é‡è¦æ€§ç»Ÿè®¡)")
    print("3. ğŸ“‹ ç»¼åˆæŠ¥å‘Šç”Ÿæˆ")
    print()
    
    confirm = input("æ˜¯å¦å¼€å§‹å®Œæ•´åˆ†æ? (y/n): ").strip().lower()
    
    if confirm == 'y':
        success = run_complete_analysis()
        if success:
            print("\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆ!")
            print("ğŸ“– æŸ¥çœ‹æ‰§è¡Œæ‘˜è¦: dataset/datasets/final_analysis_report/executive_summary.md")
        else:
            print("\nâŒ åˆ†æå¤±è´¥!")
    else:
        print("åˆ†æå·²å–æ¶ˆ")

if __name__ == "__main__":
    main()
